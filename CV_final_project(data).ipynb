{"cells":[{"cell_type":"code","execution_count":157,"metadata":{"executionInfo":{"elapsed":890,"status":"ok","timestamp":1669762161486,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"YhOOumlAyBYG"},"outputs":[],"source":["###Import Packages###\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","from PIL import Image\n","\n","from sklearn.model_selection import train_test_split\n","from skimage import io, color\n","\n","import torch\n","from torch.utils.data  import Dataset, DataLoader\n","from torchvision import transforms\n","import torchvision.transforms.functional as TF\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","from gensim.models import Word2Vec\n","\n","import re\n"]},{"cell_type":"markdown","metadata":{"id":"gSqhEXA9qGC3"},"source":["##Upload Data and unzip them"]},{"cell_type":"code","execution_count":158,"metadata":{"id":"z7U0xJbv8guL","executionInfo":{"status":"ok","timestamp":1669762164288,"user_tz":300,"elapsed":6,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"}}},"outputs":[],"source":["# Un-comment this section if need to remove any folder/directory\n","# !rm -rf /content/data"]},{"cell_type":"code","execution_count":159,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4726,"status":"ok","timestamp":1669762169010,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"FsuCUwNMD2xq","outputId":"40c221b3-f053-49ab-951d-9187ffb84739"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Connect to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["df = pd.read_csv('/content/drive/MyDrive/CV_Final_Project_Data/data/annot.csv', low_memory = False)"],"metadata":{"id":"IjvH48ioT8Ak","executionInfo":{"status":"ok","timestamp":1669762169598,"user_tz":300,"elapsed":591,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"}}},"execution_count":160,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"bupgaYCqUFom","executionInfo":{"status":"ok","timestamp":1669762169598,"user_tz":300,"elapsed":10,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"}},"outputId":"76c31163-c360-43da-b7e5-fd5aa6c37308"},"execution_count":161,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           image_id                                         Unnamed: 0  \\\n","0  0000e8b36676338b                   [761457, 761458, 761459, 761460]   \n","1  00010bf498b64bab  [684409, 684410, 684411, 684412, 684413, 68441...   \n","2  0001c6bf48e16ab2   [528078, 528079, 528081, 528082, 528083, 528084]   \n","3  000228608388803f           [206509, 206512, 206515, 206516, 206520]   \n","4  0002c799b0cd7412  [384584, 384585, 384586, 384587, 384588, 38458...   \n","\n","                                                  id  \\\n","0  ['0000e8b36676338b_1', '0000e8b36676338b_2', '...   \n","1  ['00010bf498b64bab_1', '00010bf498b64bab_2', '...   \n","2  ['0001c6bf48e16ab2_1', '0001c6bf48e16ab2_2', '...   \n","3  ['000228608388803f_1', '000228608388803f_4', '...   \n","4  ['0002c799b0cd7412_1', '0002c799b0cd7412_2', '...   \n","\n","                                                bbox  \\\n","0  ['[308.0, 135.8, 45.96, 17.33]', '[383.8, 140....   \n","1  ['[189.71, 252.79, 70.38, 46.75]', '[254.95, 2...   \n","2  ['[605.88, 326.58, 126.68, 33.3]', '[733.87, 3...   \n","3  ['[189.31, 601.3, 117.66, 38.44]', '[265.87, 6...   \n","4  ['[20.74, 82.95, 139.67, 38.19]', '[869.67, 14...   \n","\n","                                         utf8_string  \\\n","0                  ['FELIX', 'PRIVAT', 'DBU', '889']   \n","1  ['TEQU', 'A', 'KOLA', '28', 'MZ', '2387', 'AMS...   \n","2  ['NISSAN', 'GENISS', 'NISSAN', 'LIVINA', 'GENI...   \n","3   ['SF7533', 'Count', 'FOR', 'SALE', '0274390059']   \n","4  ['Percussion', 'OCCTA', 'IS', 'GLAD', 'TO', 'W...   \n","\n","                                              points  \\\n","0  ['[313.24, 135.8, 353.96, 136.2, 348.72, 153.1...   \n","1  ['[189.71, 255.87, 189.71, 255.87, 259.58, 252...   \n","2  ['[605.88, 329.19, 731.91, 326.58, 732.56, 358...   \n","3  ['[189.6, 603.06, 306.97, 601.3, 306.97, 639.7...   \n","4  ['[26.2, 82.95, 160.41, 90.58, 160.41, 121.14,...   \n","\n","                                                area  \n","0                  [796.49, 1517.05, 883.91, 918.83]  \n","1  [3290.26, 1126.99, 2379.67, 302.83, 294.12, 50...  \n","2  [4218.44, 4167.7, 2114.88, 293.55, 1707.29, 21...  \n","3     [4522.85, 175.86, 9135.32, 10691.15, 20722.37]  \n","4  [5334.0, 8605.76, 1583.36, 4725.68, 1335.97, 8...  "],"text/html":["\n","  <div id=\"df-acab42d0-2e49-4a6d-aa03-c007d66884da\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_id</th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>bbox</th>\n","      <th>utf8_string</th>\n","      <th>points</th>\n","      <th>area</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000e8b36676338b</td>\n","      <td>[761457, 761458, 761459, 761460]</td>\n","      <td>['0000e8b36676338b_1', '0000e8b36676338b_2', '...</td>\n","      <td>['[308.0, 135.8, 45.96, 17.33]', '[383.8, 140....</td>\n","      <td>['FELIX', 'PRIVAT', 'DBU', '889']</td>\n","      <td>['[313.24, 135.8, 353.96, 136.2, 348.72, 153.1...</td>\n","      <td>[796.49, 1517.05, 883.91, 918.83]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00010bf498b64bab</td>\n","      <td>[684409, 684410, 684411, 684412, 684413, 68441...</td>\n","      <td>['00010bf498b64bab_1', '00010bf498b64bab_2', '...</td>\n","      <td>['[189.71, 252.79, 70.38, 46.75]', '[254.95, 2...</td>\n","      <td>['TEQU', 'A', 'KOLA', '28', 'MZ', '2387', 'AMS...</td>\n","      <td>['[189.71, 255.87, 189.71, 255.87, 259.58, 252...</td>\n","      <td>[3290.26, 1126.99, 2379.67, 302.83, 294.12, 50...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0001c6bf48e16ab2</td>\n","      <td>[528078, 528079, 528081, 528082, 528083, 528084]</td>\n","      <td>['0001c6bf48e16ab2_1', '0001c6bf48e16ab2_2', '...</td>\n","      <td>['[605.88, 326.58, 126.68, 33.3]', '[733.87, 3...</td>\n","      <td>['NISSAN', 'GENISS', 'NISSAN', 'LIVINA', 'GENI...</td>\n","      <td>['[605.88, 329.19, 731.91, 326.58, 732.56, 358...</td>\n","      <td>[4218.44, 4167.7, 2114.88, 293.55, 1707.29, 21...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>000228608388803f</td>\n","      <td>[206509, 206512, 206515, 206516, 206520]</td>\n","      <td>['000228608388803f_1', '000228608388803f_4', '...</td>\n","      <td>['[189.31, 601.3, 117.66, 38.44]', '[265.87, 6...</td>\n","      <td>['SF7533', 'Count', 'FOR', 'SALE', '0274390059']</td>\n","      <td>['[189.6, 603.06, 306.97, 601.3, 306.97, 639.7...</td>\n","      <td>[4522.85, 175.86, 9135.32, 10691.15, 20722.37]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0002c799b0cd7412</td>\n","      <td>[384584, 384585, 384586, 384587, 384588, 38458...</td>\n","      <td>['0002c799b0cd7412_1', '0002c799b0cd7412_2', '...</td>\n","      <td>['[20.74, 82.95, 139.67, 38.19]', '[869.67, 14...</td>\n","      <td>['Percussion', 'OCCTA', 'IS', 'GLAD', 'TO', 'W...</td>\n","      <td>['[26.2, 82.95, 160.41, 90.58, 160.41, 121.14,...</td>\n","      <td>[5334.0, 8605.76, 1583.36, 4725.68, 1335.97, 8...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acab42d0-2e49-4a6d-aa03-c007d66884da')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-acab42d0-2e49-4a6d-aa03-c007d66884da button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-acab42d0-2e49-4a6d-aa03-c007d66884da');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":161}]},{"cell_type":"code","source":["# in utf8_string, get the max length from each row\n","def get_max_length(utf8_string):\n","    max_length = 0\n","    save_id = 0\n","    for i in range(len(utf8_string)):\n","        if len(utf8_string[i]) > max_length:\n","            max_length = len(utf8_string[i])\n","            save_id = i\n","    # get image_id\n","    image_id = df.iloc[i,0]\n","    return image_id, max_length\n","get_max_length(df['utf8_string'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dlIXVbkrVLTt","executionInfo":{"status":"ok","timestamp":1669762169599,"user_tz":300,"elapsed":10,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"}},"outputId":"172ffc22-5dc8-4d76-b64d-4df8050ec6eb"},"execution_count":162,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('fff91551089c59dd', 99)"]},"metadata":{},"execution_count":162}]},{"cell_type":"code","source":["# get longest word\n","def get_longest_word(utf8_string):\n","    longest_word = ''\n","    save_id = 0\n","    for i in range(len(utf8_string)):\n","        for word in utf8_string[i].split():\n","            if len(word) > len(longest_word):\n","                longest_word = word\n","                save_id = i\n","    # get image id from save_id from image_id column using save_id as index\n","    image_id = df.iloc[i,0]\n","    return longest_word\n","len(get_longest_word(df['utf8_string']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KW8Jlq9XWRHu","executionInfo":{"status":"ok","timestamp":1669764206294,"user_tz":300,"elapsed":5,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"}},"outputId":"a8053a43-9639-42eb-a60c-d65163edb58d"},"execution_count":175,"outputs":[{"output_type":"execute_result","data":{"text/plain":["45"]},"metadata":{},"execution_count":175}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgoobLYsCmra"},"outputs":[],"source":["# !mkdir data/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TZ9Lc_K1Pvd"},"outputs":[],"source":["###Unzip DATA###\n","\n","#Before run the code section, manually upload data to the file space / work space\n","# !unzip /content/original_img.zip -d /content/data/\n","# !unzip /content/masked_img.zip -d /content/data/\n","# os.rename('/content/data/Images','/content/data/original_img')\n","\n","# 7min16sec to unzip\n","# ! unzip /content/drive/MyDrive/CSCI334301_ComputerVision/Project/Dataset/archive.zip -d /content/drive/MyDrive/CSCI334301_ComputerVision/Project/Dataset/"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":1030,"status":"ok","timestamp":1669755916941,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"yWRoCbD_2EPF"},"outputs":[],"source":["###Functions for Pre-Process DATA###\n","def convert_one_channel(img):\n","    #some images have 3 channels , although they are grayscale image\n","    if len(img.shape)>2:\n","        img=img[:,:,0]\n","        return img\n","    else:\n","        return img\n","\n","\n","# ress1=Image.open('/content/data/original_img/1.png') #'/content/d/masked_img/1.png'\n","# ress2=Image.open('/content/data/masked_img/1.png')\n","# img1=ress1.resize((1540,640), Image.ANTIALIAS)\n","# img2=ress2.resize((1540,640), Image.ANTIALIAS)\n","\n","# fig = plt.figure(figsize = (32,32))\n","# ax = fig.add_subplot(2, 2, 1) \n","# plt.imshow(img1)\n","# ax = fig.add_subplot(2, 2, 2) \n","# plt.imshow(img2)\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669510568709,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"zkhh0YRU7iHD","outputId":"efb43e2f-a014-439a-8238-48b76a1373aa"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 2160x504 with 0 Axes>"]},"metadata":{}}],"source":["# ###display some processed result to double check\n","# fig = plt.figure(figsize = (30,7))\n","# # for index in range(7):\n","# #   file_path1 = os.path.join('/content/data/original_img', str(index+1)+'.png')\n","# #   file_path2 = os.path.join('/content/data/masked_img', str(index+1)+'.png')\n","# #   # print(file_path2)\n","# #   ax = fig.add_subplot(2, 7, index+1) \n","# #   plt.imshow(pre_images((1540,640),file_path1))  #show result of converting every img to one color channel\n","# #   # plt.imshow(cv2.imread(file_path1))\n","    \n","# #   ax = fig.add_subplot(2, 7, index+8)\n","# #   plt.imshow(resize((1540,640),file_path2))\n","# #   # plt.imshow(cv2.imread(file_path2))\n","# plt.show()\n","# #notice that some images has no teeth, this will make training harder"]},{"cell_type":"markdown","metadata":{"id":"iuSrfdLnq8_c"},"source":["#Loader"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1669755918537,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"B4ZfZSGPnGij"},"outputs":[],"source":["def pad_img(path):\n","  # read image\n","  img = Image.open(path)\n","  img = np.array(img)\n","  old_image_height, old_image_width, channels = img.shape\n","\n","  #rows_to_add = 16 - (old_image_width % 16)\n","  #cols_to_add = 16 - (old_image_height % 16)\n","\n","  # create new image of desired size and color (blue) for padding\n","  new_image_width = 1536\n","  new_image_height = 1536\n","  #new_image_width = old_image_width + rows_to_add\n","  #new_image_height = old_image_height + cols_to_add\n","\n","  color = (0,0,0)\n","  result = np.full((new_image_height,new_image_width, channels), color, dtype=np.uint8)\n","\n","  # compute center offset\n","  #x_center = (new_image_width - old_image_width) // 2\n","  #y_center = (new_image_height - old_image_height) // 2\n","\n","  # copy img image into center of result image\n","  #result[y_center:y_center+old_image_height, x_center:x_center+old_image_width] = img\n","\n","  # copy img image into upper left corner of result image\n","  result[0:old_image_height, 0:old_image_width] = img\n","\n","  return result"]},{"cell_type":"code","execution_count":171,"metadata":{"executionInfo":{"elapsed":499,"status":"ok","timestamp":1669763591406,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"LLVmJSaePJ0q"},"outputs":[],"source":["# WHICH ONE?\n","# Text OCR Dataloader \n","rest_set_size = 0.3\n","test_set_size = 0.5\n","class dset(Dataset):\n","  def __init__(self, root_dir, train=True,test=True,transformX = None, transformY = None):\n","        #self.pixel_file = pd.read_csv(os.path.join(root_dir, 'sample.csv'))\n","        self.root_dir = root_dir\n","        self.transformX = transformX\n","        self.transformY = transformY\n","        self.train = train\n","        self.test = test\n","\n","        # Only useful columns are: id, width, height\n","        self.images_df = pd.read_csv(f'{self.root_dir}img.csv')\n","        # Only Useful colums are: id, image_id, bbox, utf8_string\n","        annotations_df = pd.read_csv(f'{self.root_dir}annot.csv')\n","\n","        # process rows with puctuaitons in text\n","        # TODO\n","        \n","        # if data in df have same image_id, group them together\n","        annotations_df_grouped = annotations_df.groupby('image_id').agg(lambda x: list(x))\n","        \n","        # 70% tain, 15% valid, 15% test\n","        self.train_data, self.rest_data = train_test_split(annotations_df_grouped, test_size = rest_set_size, random_state = 5)\n","        self.validation_data, self.test_data = train_test_split(annotations_df_grouped, test_size = test_set_size, random_state = 5)\n","\n","    \n","\n","  # TODO: implement train, val, and test set length\n","  def __len__(self):\n","    if self.train:\n","      length = len(self.train_data)\n","    elif self.test:\n","      length = len(self.test_data)\n","    else:\n","      length = len(self.validation_data)\n","    return length\n","  \n","\n","  # for now, this will return:\n","  # X: the image (padded)\n","  # Y: the list of bounding boxes\n","  def __getitem__(self, index):\n","    # here is how to retrieve row \"names\" : self.train_data.index.values[index]\n","    filename = \"\"\n","    if self.train:\n","      filename = self.train_data.index.values[index]\n","    elif self.test:\n","      filename = self.test_data.index.values[index]\n","    else:\n","      filename = self.validation_data.index.values[index]\n","    \n","    #print(f'{self.root_dir}train_val_images/train_images/{filename}.jpg')\n","    '''\n","    imx = Image.open(f'{self.root_dir}train_val_images/train_images/{filename}.jpg')\n","    imx = np.asarray(imx)\n","    # padding\n","    shape = imx.shape\n","    rows = shape[0]\n","    cols = shape[1]\n","    rows_to_add = 16 - (rows % 16)\n","    cols_to_add = 16 - (cols % 16)\n","    imx = np.pad(imx, ((0, rows_to_add), (0, cols_to_add)), 'constant')\n","    '''\n","    imx = pad_img(f'{self.root_dir}train_val_images/train_images/{filename}.jpg')\n","\n","\n","    if self.train:\n","      annot = self.train_data.loc[filename, 'bbox']\n","      text = self.train_data.loc[filename, 'utf8_string']\n","    elif self.test:\n","      annot = self.test_data.loc[filename, 'bbox']\n","      text = self.test_data.loc[filename, 'utf8_string']\n","    else:\n","      annot = self.validation_data.loc[filename, 'bbox']\n","      text = self.validation_data.loc[filename, 'utf8_string']\n","    \n","    # for each letter/digit in text, map them into an integer value between 0 to 36\n","    # 00-09: 0-9\n","    # 10-35: A-Z\n","    # add a 36 in between each word\n","    int_text = []\n","    new_text = re.sub(r'[^\\w\\s]','',str(text))\n","    new_text = new_text.split()\n","    length = len(new_text)\n","    n = ''\n","    # print(new_text, type(new_text))\n","    for t in new_text:\n","      # print(t)\n","      temp_text = []\n","      for i in range(len(t)):\n","        # print(t[i])\n","        if t[i].isdigit():\n","          n = int(t[i])\n","        elif t[i].isalpha():\n","          n = int(ord(t[i].upper()) - 55)\n","        # if i == length - 1:\n","        #   n = 37\n","        temp_text.append(n)\n","      int_text.append(temp_text)\n","    # for i in range(length):\n","    #   if t[i].isdigit():\n","    #     n += '0' + str(t[i])\n","    #   elif t[i].isalpha():\n","    #     n += str(ord(t[i].upper()) - 55)\n","    #   else:\n","    #     n += '36'\n","    #   n += ' '\n","    #   if i == length - 1:\n","    #     n += '37'\n","    # int_text.append(n)\n","\n","    # sample = {'image': imx, 'annotation': annot, 'text': vec_arr}\n","    int_text = torch.IntTensor(int_text)\n","    sample = {'image': imx, 'annotation': annot, 'text': text, 'int_text': int_text}\n","    return sample\n","\n","#path = '/content/drive/MyDrive/CSCI334301_ComputerVision/Project/Dataset/train_val_images/train_images/00c359f294f7dcd9.jpg'\n","#img = pad_img(path)\n"]},{"cell_type":"code","execution_count":172,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"executionInfo":{"elapsed":503,"status":"error","timestamp":1669763599779,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"OE6zWVI_m_Dt","outputId":"3363f03b-5f86-42d3-d981-8b6af1446a2e"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-172-82f4f07dedb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# OCRdata = dset('/content/drive/MyDrive/CSCI334301_ComputerVision/Project/Dataset/', train=True,test=False,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mOCRdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/CV_Final_Project_Data/data/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOCRdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-171-dd9e96407321>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# sample = {'image': imx, 'annotation': annot, 'text': vec_arr}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mint_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annotation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 8 at dim 1 (got 3)"]}],"source":["# OCRdata = dset('/content/drive/MyDrive/CSCI334301_ComputerVision/Project/Dataset/', train=True,test=False,)\n","OCRdata = dset('/content/drive/MyDrive/CV_Final_Project_Data/data/')\n","data = OCRdata.__getitem__(2)\n","\n","plt.imshow(data['image'])\n","print(data['annotation'])\n","print(data['text'])\n","print(data['int_text'])"]},{"cell_type":"code","execution_count":129,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":1289,"status":"ok","timestamp":1669756755544,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"ZtATe-RLq7O7","outputId":"234b5af1-e54b-42b8-c47c-3ed91cd1988d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'0868e18f64b83259'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":129}],"source":["#test\n","OCRdata.train_data.index.values[0]"]},{"cell_type":"code","execution_count":130,"metadata":{"executionInfo":{"elapsed":5736,"status":"ok","timestamp":1669756762346,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"gtBEZ2EU06re"},"outputs":[],"source":["###initialize data_loaders\n","tx_X = transforms.Compose([transforms.ToTensor(),\n","              transforms.Normalize((0.5,), (0.5,))])\n","tx_Y = transforms.Compose([transforms.ToTensor()\n","                        ])\n","\n","# train_data = dset('/content/drive/MyDrive/CSCI334301_ComputerVision/Project/Dataset/', train=True, test=False, transformX = tx_X, transformY = tx_Y)\n","# validation_data = dset('/content/drive/MyDrive/CSCI334301_ComputerVision/Project/Dataset/', train=False,test=False,transformX = tx_X, transformY = tx_Y)\n","# test_data = dset('/content/drive/MyDrive/CSCI334301_ComputerVision/Project/Dataset/', train=False, test=True,transformX = tx_X, transformY = tx_Y\n","train_data = dset('/content/drive/MyDrive/CV_Final_Project_Data/data/', train=True, test=False, transformX = tx_X, transformY = tx_Y)\n","validation_data = dset('/content/drive/MyDrive/CV_Final_Project_Data/data/', train=False,test=False,transformX = tx_X, transformY = tx_Y)\n","test_data = dset('/content/drive/MyDrive/CV_Final_Project_Data/data/', train=False, test=True,transformX = tx_X, transformY = tx_Y)\n","\n","train_loader = DataLoader(dataset=train_data, batch_size=2, shuffle=True, num_workers=2)\n","validation_loader = DataLoader(dataset=validation_data, batch_size=2, shuffle=True, num_workers=1)\n","test_loader = DataLoader(dataset=test_data, batch_size=2, shuffle=True, num_workers=1)"]},{"cell_type":"code","execution_count":131,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669756762346,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"5kF9qQZ5Gv6k","outputId":"ea948b60-7fc3-4254-cf4b-222a5816b07f"},"outputs":[{"output_type":"stream","name":"stdout","text":["length\n","7612\n","5437\n","5438\n"]}],"source":["print('length')\n","print(len(train_loader))\n","print(len(validation_loader))\n","print(len(test_loader))"]},{"cell_type":"markdown","metadata":{"id":"JHSIaPuZrnLz"},"source":["#Model"]},{"cell_type":"code","execution_count":132,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669756762347,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"jliGHlIQrxMm"},"outputs":[],"source":["import torch.nn as nn\n","\n","\n","class BidirectionalLSTM(nn.Module):\n","\n","    def __init__(self, nIn, nHidden, nOut):\n","        super(BidirectionalLSTM, self).__init__()\n","\n","        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n","        self.embedding = nn.Linear(nHidden * 2, nOut)\n","\n","    def forward(self, input):\n","        recurrent, _ = self.rnn(input)\n","        T, b, h = recurrent.size()\n","        t_rec = recurrent.view(T * b, h)\n","\n","        output = self.embedding(t_rec)  # [T * b, nOut]\n","        output = output.view(T, b, -1)\n","\n","        return output\n","\n","\n","class CRNN(nn.Module):\n","\n","    def __init__(self, imgH, nc, nclass, nh, n_rnn=2, leakyRelu=False):\n","        super(CRNN, self).__init__()\n","        assert imgH % 16 == 0, 'imgH has to be a multiple of 16'\n","\n","        ks = [3, 3, 3, 3, 3, 3, 2]\n","        ps = [1, 1, 1, 1, 1, 1, 0]\n","        ss = [1, 1, 1, 1, 1, 1, 1]\n","        nm = [64, 128, 256, 256, 512, 512, 512]\n","\n","        cnn = nn.Sequential()\n","\n","        def convRelu(i, batchNormalization=False):\n","            nIn = nc if i == 0 else nm[i - 1]\n","            nOut = nm[i]\n","            cnn.add_module('conv{0}'.format(i),\n","                           nn.Conv2d(nIn, nOut, ks[i], ss[i], ps[i]))\n","            if batchNormalization:\n","                cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut))\n","            if leakyRelu:\n","                cnn.add_module('relu{0}'.format(i),\n","                               nn.LeakyReLU(0.2, inplace=True))\n","            else:\n","                cnn.add_module('relu{0}'.format(i), nn.ReLU(True))\n","\n","        convRelu(0)\n","        cnn.add_module('pooling{0}'.format(0), nn.MaxPool2d(2, 2))  # 64x16x64\n","        convRelu(1)\n","        cnn.add_module('pooling{0}'.format(1), nn.MaxPool2d(2, 2))  # 128x8x32\n","        convRelu(2, True)\n","        convRelu(3)\n","        cnn.add_module('pooling{0}'.format(2),\n","                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 256x4x16\n","        convRelu(4, True)\n","        convRelu(5)\n","        cnn.add_module('pooling{0}'.format(3),\n","                       nn.MaxPool2d((2, 2), (2, 1), (0, 1)))  # 512x2x16\n","        convRelu(6, True)  # 512x1x16\n","\n","        self.cnn = cnn\n","        self.rnn = nn.Sequential(\n","            BidirectionalLSTM(512, nh, nh),\n","            BidirectionalLSTM(nh, nh, nclass))\n","\n","    def forward(self, input):\n","        # conv features\n","        conv = self.cnn(input)\n","        b, c, h, w = conv.size()\n","        assert h == 1, \"the height of conv must be 1\"\n","        conv = conv.squeeze(2)\n","        conv = conv.permute(2, 0, 1)  # [w, b, c]\n","\n","        # rnn features\n","        output = self.rnn(conv)\n","\n","        return output"]},{"cell_type":"code","execution_count":133,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669756762348,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"LL4p022nthP1"},"outputs":[],"source":["model = CRNN(1152, 3, 37, 256)\n","if torch.cuda.is_available():\n","    model = model.to('cuda')"]},{"cell_type":"code","execution_count":134,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1669756763030,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"Plt2mNuZwwNU","outputId":"584e1702-50fe-4581-98b2-008b33bf37af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.modules of CRNN(\n","  (cnn): Sequential(\n","    (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (relu0): ReLU(inplace=True)\n","    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (relu1): ReLU(inplace=True)\n","    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu2): ReLU(inplace=True)\n","    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (relu3): ReLU(inplace=True)\n","    (pooling2): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n","    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu4): ReLU(inplace=True)\n","    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (relu5): ReLU(inplace=True)\n","    (pooling3): MaxPool2d(kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n","    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n","    (batchnorm6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu6): ReLU(inplace=True)\n","  )\n","  (rnn): Sequential(\n","    (0): BidirectionalLSTM(\n","      (rnn): LSTM(512, 256, bidirectional=True)\n","      (embedding): Linear(in_features=512, out_features=256, bias=True)\n","    )\n","    (1): BidirectionalLSTM(\n","      (rnn): LSTM(256, 256, bidirectional=True)\n","      (embedding): Linear(in_features=512, out_features=37, bias=True)\n","    )\n","  )\n",")>"]},"metadata":{},"execution_count":134}],"source":["model.modules"]},{"cell_type":"markdown","metadata":{"id":"pwEXeZYCtX-Q"},"source":["#Loss and Optimizer"]},{"cell_type":"code","execution_count":135,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669756764956,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"tREq1zNKtcuB"},"outputs":[],"source":["# Using Adam as our optimizer \n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001) # weight_decay="]},{"cell_type":"code","execution_count":136,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1669756764956,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"},"user_tz":300},"id":"h55vgYgjuOp_"},"outputs":[],"source":["# Using Loss()\n","criterion = nn.CTCLoss()"]},{"cell_type":"markdown","metadata":{"id":"ndGy12O0wkA2"},"source":["#Train and Validation (TO DO)"]},{"cell_type":"code","execution_count":137,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":568},"id":"mDgFaXQdxprz","executionInfo":{"status":"error","timestamp":1669756771146,"user_tz":300,"elapsed":2619,"user":{"displayName":"Jeremy Chan","userId":"10954075520389224682"}},"outputId":"ea851de2-7c57-4c5d-8c11-80527270187c"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-137-d36864fc1c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-137-d36864fc1c34>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 160, in default_collate\n    return elem_type({key: default_collate([d[key] for d in batch]) for key in elem})\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 160, in <dictcomp>\n    return elem_type({key: default_collate([d[key] for d in batch]) for key in elem})\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\", line 171, in default_collate\n    raise RuntimeError('each element in list of batch should be of equal size')\nRuntimeError: each element in list of batch should be of equal size\n"]}],"source":["# # training the model\n","# # https://github.com/meijieru/crnn.pytorch/blob/master/train.py\n","# def train(model, train_loader, validation_loader, optimizer, criterion, epochs):\n","#     for epoch in range(epochs):\n","#         model.train()\n","#         train_loss = 0\n","#         for i, item, in enumerate(train_loader):\n","#             if torch.cuda.is_available():\n","#                 item['image'] = item['image'].to('cuda')\n","#                 print(item['text'])\n","#                 break\n","#                 # item['text'] = item['text'].to('cuda')\n","#             # convert text to int, image to float tensor\n","#             item['image'] = item['image'].type(torch.FloatTensor)\n","#             item['text'] = item['text'].type(torch.LongTensor)\n","            \n","#             # forward pass\n","#             output = model(item['image'])\n","#             output = output.permute(1, 0, 2)\n","#             output = output.log_softmax(2)\n","#             output = output.permute(1, 0, 2)\n","#             # calculate loss\n","#             loss = criterion(output, item['text'], torch.IntTensor([output.size(0)] * item['image'].size(0)), torch.IntTensor([item['text'].size(0)] * item['image'].size(0)))\n","#             # backward pass\n","#             optimizer.zero_grad()\n","#             loss.backward()\n","#             optimizer.step()\n","#             train_loss += loss.item()\n","#             if i % 100 == 0:\n","#                 print('Epoch: {}, Batch: {}, Loss: {}'.format(epoch, i, loss.item()))\n","#         print('Epoch: {}, Train Loss: {}'.format(epoch, train_loss / len(train_loader)))\n","\n","# model = train(model, train_loader, validation_loader, optimizer, criterion, 10)\n","# training the model\n","# https://github.com/meijieru/crnn.pytorch/blob/master/train.py\n","def train(model, train_loader, optimizer, criterion, epoch):\n","    model.train()\n","    for batch_idx, sample in enumerate(train_loader):\n","        if torch.cuda.is_available():\n","            data = data.to('cuda')\n","            image = sample['image'].to('cuda')\n","            target = sample['int_text'].to('cuda')\n","        optimizer.zero_grad()\n","        output = model(data)\n","        output = output.log_softmax(2)\n","        output = output.permute(1, 0, 2)\n","        target = target.long()\n","        target = target.permute(1, 0)\n","        input_lengths = torch.full(size=(output.size(0),), fill_value=output.size(1), dtype=torch.long)\n","        target_lengths = torch.full(size=(target.size(0),), fill_value=target.size(1), dtype=torch.long)\n","        loss = criterion(output, target, input_lengths, target_lengths)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 10 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","# train\n","for epoch in range(1, 10):\n","    train(model, train_loader, optimizer, criterion, epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRe7PwFDxuiR"},"outputs":[],"source":["# validation\n","def validation(model, validation_loader, criterion):\n","    model.eval()\n","    validation_loss = 0\n","    for i, item, in enumerate(validation_loader):\n","        if torch.cuda.is_available():\n","            item['image'] = item['image'].to('cuda')\n","            item['text'] = item['text'].to('cuda')\n","        # convert text to int, image to float tensor\n","        item['image'] = item['image'].type(torch.FloatTensor)\n","        item['text'] = item['text'].type(torch.LongTensor)\n","        # forward pass\n","        output = model(item['image'])\n","        output = output.permute(1, 0, 2)\n","        output = output.log_softmax(2)\n","        output = output.permute(1, 0, 2)\n","        # calculate loss\n","        loss = criterion(output, item['text'], torch.IntTensor([output.size(0)] * item['image'].size(0)), torch.IntTensor([item['text'].size(0)] * item['image'].size(0)))\n","        validation_loss += loss.item()\n","    print('Validation Loss: {}'.format(validation_loss / len(validation_loader)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q_fTSskTxvwq"},"outputs":[],"source":["# testing\n","def test(model, test_loader):\n","    model.eval()\n","    for i, item, in enumerate(test_loader):\n","        if torch.cuda.is_available():\n","            item['image'] = item['image'].to('cuda')\n","            item['text'] = item['text'].to('cuda')\n","        # convert text to int, image to float tensor\n","        item['image'] = item['image'].type(torch.FloatTensor)\n","        item['text'] = item['text'].type(torch.LongTensor)\n","        # forward pass\n","        output = model(item['image'])\n","        output = output.permute(1, 0, 2)\n","        output = output.log_softmax(2)\n","        output = output.permute(1, 0, 2)\n","        # calculate loss\n","        loss = criterion(output, item['text'], torch.IntTensor([output.size(0)] * item['image'].size(0)), torch.IntTensor([item['text'].size(0)] * item['image'].size(0)))\n","        print('Test Loss: {}'.format(loss.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6wYBwalu6gy"},"outputs":[],"source":["# # old\n","# from tqdm.notebook import tqdm\n","# def train(model, criterion, epochs = 5, verbose=False):\n","#   if not train_hist:\n","#     train_hist = []\n","#   if not val_hist:\n","#     val_hist = []\n","    \n","#   torch.cuda.empty_cache()\n","    \n","#   tqdm.write(\"====== Training Started ======\")\n","#   epochs_completed = 0\n","#   for e in tqdm(range(epochs), position=0, desc=\"Epochs\", leave=False, colour='green'):\n","#     train_running_loss = 0.0\n","#     validation_running_loss = 0.0\n","#     ct = 0.0\n","    \n","#     model.train()\n","    \n","#     # print(\"Losses are reset to:\", train_running_loss, validation_running_loss, ct)\n","#     for ith_batch, sample in tqdm(enumerate(train_loader), position=1, desc=\"Batches\", leave=False, total=len(train_loader), colour='blue'):\n","#       X, Y = sample['image'], sample['annotation']\n","\n","#       if torch.cuda.is_available():\n","#         X = X.to('cuda')\n","#         Y = Y.to('cuda')\n","\n","#       y_pred = model(X)\n","#     # out = (y_pred + 0.5).int().float()\n","      \n","#       # loss = criterion(y_pred, Y) #* 0.70 + 0.30 * dice_loss(y_pred, y_train)\n","#       loss=0.3*dice_loss(y_pred, Y)+0.7*criterion(y_pred, Y)\n","#       optimizer.zero_grad()\n","#       loss.backward()\n","#       optimizer.step()\n","#       if verbose and ith_batch % 10 == 0 and ith_batch != 0:\n","#         # print(\"This item's loss:\", f'{loss.item()}')\n","#         # print(\"This pred started with\", y_pred[0][0][0][0:10])\n","#         tqdm.write('Epoch: ', e + 1, 'Batch: ', ith_batch, 'Curr Epoch Loss: ', f'{train_running_loss / ct:0.3f}')\n","        \n","#       train_running_loss += loss.item()\n","#       train_hist.append(loss.item())\n","#       ct += 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XEXjVn8bv8Gt"},"outputs":[],"source":["total_epochs=0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkDimd6AwAEk"},"outputs":[],"source":["num_epochs = 100\n","# and visualize the full training graph\n","completed_epochs = train(model, criterion, epochs=num_epochs, verbose=False)\n","total_epochs+=completed_epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UngM-hKjVKG"},"outputs":[],"source":["torch.save(model.state_dict(),'/content/best_unet_051722_v1.pth')"]},{"cell_type":"markdown","metadata":{"id":"DFJ95L9CZinB"},"source":["# Test"]},{"cell_type":"markdown","metadata":{"id":"NmZvdLKaX-Rx"},"source":["Once the training is completed, we just need to upload the model and run from here."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0KI8dk22GfD"},"outputs":[],"source":["# Load saved model\n","model = Class()\n","model.load_state_dict(torch.load('/content/best_unet_051722_v1.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GDb9jdBrsxFo"},"outputs":[],"source":["###Load DATA\n","\n","test_set_size = 0.5\n","class dset(Dataset):\n","    def __init__(self, root_dir, train=True,test=True,transformX = None, transformY = None):\n","        self.pixel_file = pd.read_csv(os.path.join(root_dir, 'sample.csv'))\n","        self.root_dir = root_dir\n","        self.transformX = transformX\n","        self.transformY = transformY\n","        self.train = train\n","        self.test = test\n","        \n","        # split the dataset to train and rest\n","        # split the rest to validation and test\n","        self.train_data, self.test_data = train_test_split(self.pixel_file, test_size = test_set_size, random_state = 5)\n","        # self.validation_data, self.test_data = train_test_split(self.rest_data, test_size = test_set_size, random_state = 5)\n","\n","    def __len__(self):\n","        if self.train:\n","          length = len(self.train_data)\n","        elif self.test:\n","          length = len(self.test_data)\n","        else:\n","          length = len(self.validation_data)\n","        return length\n","    \n","    def __getitem__(self, index):\n","        if self.train:\n","          imx_name = os.path.join(self.root_dir, 'original_img',self.train_data.iloc[index, 0])\n","          imy_name = os.path.join(self.root_dir, 'original_img',self.train_data.iloc[index, 0].replace('.png','_m.png'))\n","        elif self.test:\n","          imx_name = os.path.join(self.root_dir, 'original_img',self.test_data.iloc[index, 0])\n","          imy_name = os.path.join(self.root_dir, 'original_img',self.test_data.iloc[index, 0].replace('.png','_m.png'))\n","        else:\n","          imx_name = os.path.join(self.root_dir, 'original_img', self.validation_data.iloc[index, 0])\n","          imy_name = os.path.join(self.root_dir, 'original_img',self.validation_data.iloc[index, 0].replace('.png','_m.png'))\n","        \n","        imx = Image.open(imx_name)\n","        imy = Image.open(imy_name).convert('L')\n","\n","        if self.transformX:\n","            imx = self.transformX(imx)\n","            imy = self.transformY(imy)\n","      \n","        sample = {'image': imx, 'annotation': imy}\n","        return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WSk2x_xjtERZ"},"outputs":[],"source":["tx_X = transforms.Compose([ transforms.Resize((512, 512)),\n","                              transforms.ToTensor(),\n","                           transforms.Normalize((0.5,), (0.5,))\n","                              ])\n","tx_Y = transforms.Compose([ transforms.Resize((512, 512)),\n","                              transforms.ToTensor()\n","                              ])\n","train_data = dset('/content/data', train=True, test=False, transformX = tx_X, transformY = tx_Y)\n","test_data = dset('/content/data', train=False, test=True,transformX = tx_X, transformY = tx_Y)\n","\n","train_loader = DataLoader(dataset=train_data, batch_size=2, shuffle=True, num_workers=2)\n","test_loader = DataLoader(dataset=test_data, batch_size=2, shuffle=True, num_workers=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tn8qB812Zlt0"},"outputs":[],"source":["#test\n","def avg_dice_index(dataloader): \n","    dice = 0.0\n","    model.eval()\n","    with torch.no_grad():\n","        for ith_batch, sample_batched in enumerate(dataloader):\n","  \n","            X_train = sample_batched['image'].to('cuda')\n","            y_train = sample_batched['annotation'].to('cuda')\n","            \n","            y_predict = (model(X_train) + 0.5).int().float()\n","            \n","            dice += dice_index(y_predict, y_train)\n","            \n","    print(len(dataloader))\n","    avg_dice = dice / len(dataloader)\n","    \n","    return avg_dice.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4070,"status":"ok","timestamp":1652769185821,"user":{"displayName":"Yuting Ji","userId":"04759692661617013761"},"user_tz":240},"id":"33Dfz8ubgs87","outputId":"0a48c6f3-6fe0-4641-db09-0df3bf82327b"},"outputs":[{"name":"stdout","output_type":"stream","text":["29\n"]}],"source":["test_score=avg_dice_index(test_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1652769190505,"user":{"displayName":"Yuting Ji","userId":"04759692661617013761"},"user_tz":240},"id":"1dsZGwOVg1rg","outputId":"4ae79a55-3249-4543-ddd0-35bf702aea55"},"outputs":[{"name":"stdout","output_type":"stream","text":["Avergae Dice Score is: 0.9117302298545837\n","Avergae Dice Loss is: 0.08826977014541626\n"]}],"source":["print('Avergae Dice Score is:',test_score)\n","print('Avergae Dice Loss is:',1-test_score)"]},{"cell_type":"markdown","metadata":{"id":"tIlWkLx0ZpOB"},"source":["#Post-Process"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1eYcB9qx1XSULpQVUaJbZTYWUVAUBP2tL","timestamp":1668382319189}]},"gpuClass":"standard","interpreter":{"hash":"fd9765cc4a12c8f620395c2183698124ccce9dfda40da83c1115d13f985f26dc"},"kernelspec":{"display_name":"Python 3.8.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":0}